{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:51:54.164543Z",
     "start_time": "2025-12-14T18:51:54.159644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from datasets import (\n",
    "    DatasetDict,\n",
    "    Dataset\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    ")\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration,\n",
    "    Trainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    TrainingArguments,\n",
    ")\n",
    "import joblib\n",
    "\n",
    "try:\n",
    "    import tensorflow\n",
    "\n",
    "    print(\"⚠️ TensorFlow encore présent\")\n",
    "except ImportError:\n",
    "    print(\"✅ TensorFlow désinstallé\")\n",
    "\n",
    "try:\n",
    "    import transformers\n",
    "    import torch\n",
    "\n",
    "    print(f\"✅ Transformers {transformers.__version__}\")\n",
    "    print(f\"✅ PyTorch {torch.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"❌ Transformers ou PyTorch manquant\")\n"
   ],
   "id": "cbccfda2f5d3813c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TensorFlow désinstallé\n",
      "✅ Transformers 4.57.3\n",
      "✅ PyTorch 2.9.1\n"
     ]
    }
   ],
   "execution_count": 128
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-14T18:51:56.800668Z",
     "start_time": "2025-12-14T18:51:56.766295Z"
    }
   },
   "source": [
    "# Chargement dataset\n",
    "csv_path = \"../backend/app/data/raw/export_us_01.csv\"\n",
    "\n",
    "try:\n",
    "    if not os.path.exists(csv_path):\n",
    "        raise FileNotFoundError(f\"Fichier non trouvé: {csv_path}\")\n",
    "    df = pd.read_csv(csv_path, low_memory=False, sep=\";\", encoding=\"utf-8\")\n",
    "    print(f\"CSV file chargé avec succès. Nombre d'échantillons chargés: {df.shape[0]}\")\n",
    "    display(df.head())\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file chargé avec succès. Nombre d'échantillons chargés: 1118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  Issue Type         Key Priority     Status  \\\n",
       "0      Story  CODEE01-35      NaN  Cancelled   \n",
       "1      Story  CODEE01-91      NaN  Cancelled   \n",
       "2      Story  CODEE01-90      NaN  Cancelled   \n",
       "3      Story  CODEE01-55      NaN  Cancelled   \n",
       "4      Story  CODEE01-65      NaN  Cancelled   \n",
       "\n",
       "                                             Summary     Created  \\\n",
       "0  [eShop] [OUT OF SCOPE] Products recommendation...  27-03-2023   \n",
       "1        [Go-live] Activation of a B2B portal itself  27-03-2023   \n",
       "2  [Go-live] Activation of the integration with o...  27-03-2023   \n",
       "3  [Integration with CMS][OUT of the Scope]Integr...  27-03-2023   \n",
       "4  [General] Configuration of the Version Control...  27-03-2023   \n",
       "\n",
       "                                         Description Unnamed: 7 Unnamed: 8  \\\n",
       "0  As a business \\n\\nI want to system supports pr...        NaN        NaN   \n",
       "1  As a Tech \\n\\nI want to story \\n\\nSo that I ca...        NaN        NaN   \n",
       "2  As a Tech \\n\\nI want to story \\n\\nSo that I ca...        NaN        NaN   \n",
       "3  As a business \\n\\nI want to show to clients th...        NaN        NaN   \n",
       "4  As a Tech \\n\\nI want to story \\n\\nSo that I ca...        NaN        NaN   \n",
       "\n",
       "  Unnamed: 9 Unnamed: 10 Unnamed: 11  \n",
       "0        NaN         NaN         NaN  \n",
       "1        NaN         NaN         NaN  \n",
       "2        NaN         NaN         NaN  \n",
       "3        NaN         NaN         NaN  \n",
       "4        NaN         NaN         NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue Type</th>\n",
       "      <th>Key</th>\n",
       "      <th>Priority</th>\n",
       "      <th>Status</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Created</th>\n",
       "      <th>Description</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Story</td>\n",
       "      <td>CODEE01-35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>[eShop] [OUT OF SCOPE] Products recommendation...</td>\n",
       "      <td>27-03-2023</td>\n",
       "      <td>As a business \\n\\nI want to system supports pr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Story</td>\n",
       "      <td>CODEE01-91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>[Go-live] Activation of a B2B portal itself</td>\n",
       "      <td>27-03-2023</td>\n",
       "      <td>As a Tech \\n\\nI want to story \\n\\nSo that I ca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Story</td>\n",
       "      <td>CODEE01-90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>[Go-live] Activation of the integration with o...</td>\n",
       "      <td>27-03-2023</td>\n",
       "      <td>As a Tech \\n\\nI want to story \\n\\nSo that I ca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Story</td>\n",
       "      <td>CODEE01-55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>[Integration with CMS][OUT of the Scope]Integr...</td>\n",
       "      <td>27-03-2023</td>\n",
       "      <td>As a business \\n\\nI want to show to clients th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Story</td>\n",
       "      <td>CODEE01-65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cancelled</td>\n",
       "      <td>[General] Configuration of the Version Control...</td>\n",
       "      <td>27-03-2023</td>\n",
       "      <td>As a Tech \\n\\nI want to story \\n\\nSo that I ca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 129
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Préprocessing\n",
   "id": "903bafd0ebe09f77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:51:58.897219Z",
     "start_time": "2025-12-14T18:51:58.886872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Clean data\n",
    "columns = ['Key', 'Created']\n",
    "df.drop(columns=columns, inplace=True)\n",
    "\n",
    "features = ['Issue Type', 'Summary', 'Description']\n",
    "contentX = df[features].copy()\n",
    "contentX.fillna(\"\")"
   ],
   "id": "c520400b002bc5ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Issue Type                                            Summary  \\\n",
       "0         Story  [eShop] [OUT OF SCOPE] Products recommendation...   \n",
       "1         Story        [Go-live] Activation of a B2B portal itself   \n",
       "2         Story  [Go-live] Activation of the integration with o...   \n",
       "3         Story  [Integration with CMS][OUT of the Scope]Integr...   \n",
       "4         Story  [General] Configuration of the Version Control...   \n",
       "...         ...                                                ...   \n",
       "1113                                                                 \n",
       "1114                                                                 \n",
       "1115                                                                 \n",
       "1116                                                                 \n",
       "1117                                                                 \n",
       "\n",
       "                                            Description  \n",
       "0     As a business \\n\\nI want to system supports pr...  \n",
       "1     As a Tech \\n\\nI want to story \\n\\nSo that I ca...  \n",
       "2     As a Tech \\n\\nI want to story \\n\\nSo that I ca...  \n",
       "3     As a business \\n\\nI want to show to clients th...  \n",
       "4     As a Tech \\n\\nI want to story \\n\\nSo that I ca...  \n",
       "...                                                 ...  \n",
       "1113                                                     \n",
       "1114                                                     \n",
       "1115                                                     \n",
       "1116                                                     \n",
       "1117                                                     \n",
       "\n",
       "[1118 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Issue Type</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Story</td>\n",
       "      <td>[eShop] [OUT OF SCOPE] Products recommendation...</td>\n",
       "      <td>As a business \\n\\nI want to system supports pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Story</td>\n",
       "      <td>[Go-live] Activation of a B2B portal itself</td>\n",
       "      <td>As a Tech \\n\\nI want to story \\n\\nSo that I ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Story</td>\n",
       "      <td>[Go-live] Activation of the integration with o...</td>\n",
       "      <td>As a Tech \\n\\nI want to story \\n\\nSo that I ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Story</td>\n",
       "      <td>[Integration with CMS][OUT of the Scope]Integr...</td>\n",
       "      <td>As a business \\n\\nI want to show to clients th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Story</td>\n",
       "      <td>[General] Configuration of the Version Control...</td>\n",
       "      <td>As a Tech \\n\\nI want to story \\n\\nSo that I ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1118 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:52:39.117664Z",
     "start_time": "2025-12-14T18:52:39.072142Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def nettoyer_texte_description(text: str) -> str:\n",
    "    text = text.strip()\n",
    "    text = re.sub(r' +', ' ', text)  # espaces multiples\n",
    "    text = re.sub(r'\\n\\s*\\n+', '\\n', text)  # supprime lignes vides multiples\n",
    "    text = text.replace(r'\\n\\s*\\n+', '')\n",
    "    return text\n",
    "\n",
    "\n",
    "# Nettoie et normalise le texte\n",
    "def nettoyer_texte(texte):\n",
    "    texte = re.sub(r\"([.,!?'])\", r\" \\1 \", texte)\n",
    "    texte = re.sub(r\"([-●'])\", r\" \", texte)\n",
    "    return texte.strip()\n",
    "\n",
    "\n",
    "def extract_acceptance_criteria(text: str) -> List[str]:\n",
    "    text = text.replace(\"●\", \"-\")  # Remplace les bullets non standard par \"-\"\n",
    "\n",
    "    # Trouver la section \"Acceptance Criteria\"\n",
    "    match = re.search(r'Acceptance Criteria(.*)', text, re.DOTALL | re.IGNORECASE)\n",
    "    if not match:\n",
    "        return []\n",
    "\n",
    "    ac_section = match.group(1).strip()\n",
    "\n",
    "    # Découper selon les puces commençant par \"-\"\n",
    "    items = re.split(r'-\\s*', ac_section)\n",
    "    items = [i.strip() for i in items if i.strip()]\n",
    "\n",
    "    return items\n",
    "\n",
    "\n",
    "def safe_text(v):\n",
    "    if isinstance(v, float):  # couvre NaN ou nombres\n",
    "        return \"\"\n",
    "    return str(v).strip()\n",
    "\n",
    "\n",
    "def preprocess_issueType(raw_text: str) -> str:\n",
    "    return raw_text\n",
    "\n",
    "\n",
    "def preprocess_summary(raw_text: str) -> str:\n",
    "    return raw_text\n",
    "\n",
    "\n",
    "def preprocess_description(raw_text: str):\n",
    "    text = nettoyer_texte_description(raw_text)\n",
    "\n",
    "    # Résumé auto : première phrase \"As a business...\"\n",
    "    summary_match = re.search(r\"As a .*?[\\.\\n]\", text, re.IGNORECASE)\n",
    "    summary = summary_match.group(0).strip() if summary_match else \"\"\n",
    "\n",
    "    # Description : la partie avant les critères d'acceptation\n",
    "    description = re.split(r'Acceptance Criteria', text, flags=re.IGNORECASE)[0]\n",
    "    description = nettoyer_texte_description(description)\n",
    "\n",
    "    # Critères d'acceptation\n",
    "    acceptance_criteria = extract_acceptance_criteria(text)\n",
    "    acceptance_criterias = '\\n - '.join(acceptance_criteria)\n",
    "    return {\n",
    "        'content_summary': summary,\n",
    "        'description': description,\n",
    "        'acceptance_criteria': acceptance_criterias,\n",
    "    }\n",
    "\n",
    "\n",
    "resp = []\n",
    "\n",
    "for i, phrase in contentX.iterrows():\n",
    "    rawIssueType = safe_text(phrase['Issue Type'])\n",
    "    if rawIssueType == \"\":\n",
    "        rawIssueType = \"Story\" # set default value\n",
    "    rawSummary = safe_text(phrase['Summary'])\n",
    "    if rawSummary == \"\":\n",
    "        rawIssueType = \"Empty\" # set default value\n",
    "    rawDescription = safe_text(phrase['Description'])\n",
    "    # Skip empty info\n",
    "    if rawDescription != \"\":\n",
    "        issueType = preprocess_issueType(rawIssueType)\n",
    "        summary = preprocess_summary(rawSummary)\n",
    "        description = preprocess_description(rawDescription)\n",
    "        resp.append(\n",
    "            {\n",
    "                \"issue_type\": nettoyer_texte(issueType),\n",
    "                \"summary\": nettoyer_texte(rawSummary),\n",
    "                \"content_summary\": nettoyer_texte(description['content_summary']),\n",
    "                \"description\": nettoyer_texte(description['description']),\n",
    "                \"acceptance_criteria\": nettoyer_texte(description['acceptance_criteria']),\n",
    "            })\n",
    "\n",
    "print(f\"Size : {len(resp)}\")\n"
   ],
   "id": "6127f14ae5f1b5b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size : 877\n"
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:52:41.821270Z",
     "start_time": "2025-12-14T18:52:41.818604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "for i, texte in enumerate(resp[:5]):\n",
    "    print(f\"{i}.\\n{texte}\\n\")\n"
   ],
   "id": "e38d57d9ecb816c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.\n",
      "{'issue_type': 'Story', 'summary': '[eShop] [OUT OF SCOPE] Products recommendation (AI)', 'content_summary': 'As a business', 'description': 'As a business \\nI want to system supports products recommendation based on AI \\nSo that I can provide my clients better experience and the most relevant suggestions', 'acceptance_criteria': 'Universal custom LWC component with the list of recommended products that can be placed to any Community page . \\n   The Custom component will use the Einstein API for getting insights from the AI . \\n   The Einstein need to be enabled in the B2B portal once system will be launched and enough data(orders ,  cartItems) will be created there . \\n   Einstein will be turned on without custom LWC component'}\n",
      "\n",
      "1.\n",
      "{'issue_type': 'Story', 'summary': '[Go live] Activation of a B2B portal itself', 'content_summary': 'As a Tech', 'description': 'As a Tech \\nI want to story \\nSo that I can N/A', 'acceptance_criteria': ''}\n",
      "\n",
      "2.\n",
      "{'issue_type': 'Story', 'summary': '[Go live] Activation of the integration with other systems: QAD ,  MDM', 'content_summary': 'As a Tech', 'description': 'As a Tech \\nI want to story \\nSo that I can N/A', 'acceptance_criteria': ''}\n",
      "\n",
      "3.\n",
      "{'issue_type': 'Story', 'summary': '[Integration with CMS][OUT of the Scope]Integration setup between SF and CMS', 'content_summary': 'As a business', 'description': 'As a business \\nI want to show to clients the same products related content at eShop and Web site \\nSo that I can have consistency and up to date products information on all platforms', 'acceptance_criteria': 'Setup credentials\\n   Setup connection settings'}\n",
      "\n",
      "4.\n",
      "{'issue_type': 'Story', 'summary': '[General] Configuration of the Version Control System', 'content_summary': 'As a Tech', 'description': 'As a Tech \\nI want to story \\nSo that I can N/A', 'acceptance_criteria': 'Setup Git repository , access to it'}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:52:45.110393Z",
     "start_time": "2025-12-14T18:52:45.107046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define device\n",
    "\n",
    "use_mps = False\n",
    "use_fp16 = False\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    use_fp16 = True\n",
    "    print(f\"GPU NVIDIA détecté: {torch.cuda.get_device_name(0)}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    use_mps = True\n",
    "    use_fp16 = False\n",
    "    print(\"GPU Apple Silicon (MPS) détecté\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    use_mps = False\n",
    "    use_fp16 = False\n",
    "    print(\"CPU détecté\")\n",
    "\n",
    "print(f\"Model defined {device}\")"
   ],
   "id": "87bf759a4ffd4d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Apple Silicon (MPS) détecté\n",
      "Model defined mps\n"
     ]
    }
   ],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:52:57.133181Z",
     "start_time": "2025-12-14T18:52:52.742313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"google/flan-t5-base\"\n",
    "\n",
    "autoTokenizerGen = AutoTokenizer.from_pretrained(model_name)\n",
    "modelGen = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "modelGen.to(device)\n",
    "\n",
    "def normalize_tags(tag_str):\n",
    "    # split by comma, strip, lowercase, replace spaces by hyphen, remove duplicates\n",
    "    tags = [t.strip().lower().replace(\" \", \"-\") for t in tag_str.split(\",\") if t.strip()]\n",
    "    seen = []\n",
    "    for t in tags:\n",
    "        if t not in seen:\n",
    "            seen.append(t)\n",
    "    return seen\n",
    "\n",
    "\n",
    "def generate_client_sentence(target, max_length=128):\n",
    "    num_tags = 8\n",
    "    prompt = (\n",
    "        f\"\"\"Generate {num_tags} relevant tags for this description.\n",
    "        Tags should be lowercase, comma-separated, and include technologies, frameworks, and project type.\n",
    "\n",
    "        Project description: {target}\n",
    "\n",
    "        Tags:\"\"\"\n",
    "    )\n",
    "\n",
    "    inputsGen = autoTokenizerGen(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputsGen = modelGen.generate(\n",
    "            **inputsGen,\n",
    "            max_length=max_length,\n",
    "            num_beams=5,\n",
    "            no_repeat_ngram_size=3,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            early_stopping=True,\n",
    "        )\n",
    "\n",
    "    tags = autoTokenizerGen.decode(outputsGen[0], skip_special_tokens=True)\n",
    "\n",
    "    # Clean up output\n",
    "    tags = tags.strip()\n",
    "    if not tags:\n",
    "        return \"web-app, software, development\"  # Fallback\n",
    "\n",
    "    return {\n",
    "        \"target\": target,\n",
    "        \"targs\": tags,\n",
    "    }\n"
   ],
   "id": "48eb8af62d224609",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ProtocolError('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer')), '(Request ID: c78c29a3-fb56-48f1-beff-9dfefaff7db1)')' thrown while requesting HEAD https://huggingface.co/google/flan-t5-base/resolve/main/tokenizer_config.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T18:55:31.994721Z",
     "start_time": "2025-12-14T18:52:59.892285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "content_data = []\n",
    "for t in resp:\n",
    "    data = generate_client_sentence(t['description'])\n",
    "    content_data.append({\n",
    "        \"input\": data['targs'],\n",
    "        \"output\": data['target'],\n",
    "    })\n"
   ],
   "id": "f0db7cfcdd9f6e9b",
   "outputs": [],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T15:39:00.313205Z",
     "start_time": "2025-12-14T15:39:00.310778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, cd in enumerate(content_data[:5]):\n",
    "    print(f\"{i}.\\Input: \\n{cd[\"input\"]}\\nOutput: \\n{cd['output']}\\n\")"
   ],
   "id": "1af5503532385599",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.\\Input: \n",
      "technologies, frameworks, project type\n",
      "Output: \n",
      "As a business \n",
      "I want to system supports products recommendation based on AI \n",
      "So that I can provide my clients better experience and the most relevant suggestions\n",
      "\n",
      "1.\\Input: \n",
      "project type\n",
      "Output: \n",
      "As a Tech \n",
      "I want to story \n",
      "So that I can N/A\n",
      "\n",
      "2.\\Input: \n",
      "project type\n",
      "Output: \n",
      "As a Tech \n",
      "I want to story \n",
      "So that I can N/A\n",
      "\n",
      "3.\\Input: \n",
      "technologies, frameworks, project type\n",
      "Output: \n",
      "As a business \n",
      "I want to show to clients the same products related content at eShop and Web site \n",
      "So that I can have consistency and up to date products information on all platforms\n",
      "\n",
      "4.\\Input: \n",
      "project type\n",
      "Output: \n",
      "As a Tech \n",
      "I want to story \n",
      "So that I can N/A\n",
      "\n"
     ]
    }
   ],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T15:39:07.373217Z",
     "start_time": "2025-12-14T15:39:07.340237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "split = Dataset.from_list(content_data).train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": split[\"train\"],\n",
    "    \"validation\": split[\"test\"]\n",
    "})\n",
    "\n",
    "print(len(dataset_dict[\"train\"]))\n",
    "print(len(dataset_dict[\"validation\"]))"
   ],
   "id": "c2aaa02c568843ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464\n",
      "52\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T15:39:09.480204Z",
     "start_time": "2025-12-14T15:39:08.667557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the Tokenizer\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocess(batch):\n",
    "    inputs = batch[\"input\"]\n",
    "    targets = batch[\"output\"]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\").input_ids\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs\n",
    "\n",
    "tokenized = dataset_dict.map(preprocess, batched=True, remove_columns=dataset_dict[\"train\"].column_names)\n",
    "tokenized.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ],
   "id": "2ef209af4f1d88e3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 464/464 [00:00<00:00, 2445.11 examples/s]\n",
      "Map: 100%|██████████| 52/52 [00:00<00:00, 4077.39 examples/s]\n"
     ]
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T20:53:33.469513Z",
     "start_time": "2025-12-14T20:53:28.814535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # defines the rank of the update matrices\n",
    "    lora_alpha=32,  # scales the updates\n",
    "    target_modules=[\"q\", \"v\"],  # Adjust based on model architecture - attention projection modules\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\"  # sequence-to-sequence task\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "# Paramétres\n",
    "EPOCHS = 25  #25\n",
    "LEARNING_RATE = 5e-5\n",
    "\n",
    "train_batch_size = 8 if use_mps else 4\n",
    "eval_batch_size = 8 if use_mps else 4\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../target/t5_tag_generator\",\n",
    "\n",
    "    # Paramètres d'entraînement\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=train_batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "\n",
    "    # Paramètres essentiels selon le device\n",
    "    fp16=use_fp16,  # True si GPU\n",
    "    use_mps_device=use_mps,  # True si GPU mps détecté\n",
    "\n",
    "    # Optimisation\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ],
   "id": "c30a3697efe25684",
   "outputs": [],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T21:13:57.915258Z",
     "start_time": "2025-12-14T20:53:36.356737Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "40ce9c065fe9007d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='183' max='1450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 183/1450 20:08 < 2:20:58, 0.15 it/s, Epoch 3.14/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "8de0cd21c63c87980d9187f346b821cb"
     }
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[139]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/github-projets/SoftwareCrewIA/.venv/lib/python3.13/site-packages/transformers/trainer.py:2325\u001B[39m, in \u001B[36mTrainer.train\u001B[39m\u001B[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[39m\n\u001B[32m   2323\u001B[39m         hf_hub_utils.enable_progress_bars()\n\u001B[32m   2324\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m2325\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minner_training_loop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2326\u001B[39m \u001B[43m        \u001B[49m\u001B[43margs\u001B[49m\u001B[43m=\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2327\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_from_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2328\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2329\u001B[39m \u001B[43m        \u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mignore_keys_for_eval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2330\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/github-projets/SoftwareCrewIA/.venv/lib/python3.13/site-packages/transformers/trainer.py:2679\u001B[39m, in \u001B[36mTrainer._inner_training_loop\u001B[39m\u001B[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[39m\n\u001B[32m   2673\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m context():\n\u001B[32m   2674\u001B[39m     tr_loss_step = \u001B[38;5;28mself\u001B[39m.training_step(model, inputs, num_items_in_batch)\n\u001B[32m   2676\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   2677\u001B[39m     args.logging_nan_inf_filter\n\u001B[32m   2678\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_torch_xla_available()\n\u001B[32m-> \u001B[39m\u001B[32m2679\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m (torch.isnan(tr_loss_step) \u001B[38;5;129;01mor\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43misinf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtr_loss_step\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m   2680\u001B[39m ):\n\u001B[32m   2681\u001B[39m     \u001B[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001B[39;00m\n\u001B[32m   2682\u001B[39m     tr_loss = tr_loss + tr_loss / (\u001B[32m1\u001B[39m + \u001B[38;5;28mself\u001B[39m.state.global_step - \u001B[38;5;28mself\u001B[39m._globalstep_last_logged)\n\u001B[32m   2683\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T15:46:41.789784Z",
     "start_time": "2025-12-14T15:46:07.480006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_tags(query, model, tokenizer, max_length=512, num_beams=5):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(query, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512).to(\n",
    "        model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_length=max_length,\n",
    "            num_beams=num_beams,\n",
    "            early_stopping=True,\n",
    "            decoder_start_token_id=tokenizer.pad_token_id  #  required for T5\n",
    "        )\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)"
   ],
   "id": "7b320d65ec1e3e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R: \n",
      "R: \n",
      "R: As a business I want to show to clients the same products related content at eShop and Web site so that I can have consistency and up to date products information on all platforms. I want to show to clients the same products related content at eShop and Web site so that I can have consistency and up to date products information on all platforms. I want to show to clients the same products related content at eShop and Web site.\n",
      "R: \n"
     ]
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T15:31:17.897260Z",
     "start_time": "2025-12-14T15:31:17.558077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Enregistrement du modèle\n",
    "x = datetime.datetime.now()\n",
    "x = x.strftime(\"%Y-%m-%d.%H:%M:%S\")\n",
    "#modelName = f\"model_0_{x}.pkl\"\n",
    "modelName = f\"model_0.pkl\"\n",
    "\n",
    "print(f\"• enregistrement du modèle {modelName}\")\n",
    "joblib.dump(model, \"../backend/models/\" + modelName)\n",
    "print(\"• Fin de l'enregistrement' du modèle\")"
   ],
   "id": "47c44b197cd52802",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~ Enregistrement du modèle ~~~\n",
      "• enregistrement du modèle model_0_2025-12-14.16:31:17.pkl\n",
      "• Fin de l'enregistrement' du modèle\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-14T21:14:24.841158Z",
     "start_time": "2025-12-14T21:14:23.489798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "modelPath = \"../backend/models/\" + modelName\n",
    "loadedModel = joblib.load(modelPath)\n",
    "loadedModel.to(device)\n",
    "lastPrediction = generate_tags(\n",
    "    \"technologies, frameworks, project type\",\n",
    "    loadedModel,\n",
    "    modelName)\n",
    "\n",
    "print(\"Prédiction: \" + lastPrediction)\n"
   ],
   "id": "8bba71f2d877b410",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/model_0_2025-12-14.16:31:17.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[140]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      4\u001B[39m modelPath = \u001B[33m\"\u001B[39m\u001B[33m../models/model_0_2025-12-14.16:31:17.pkl\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      5\u001B[39m \u001B[38;5;66;03m# modelPath = \"../models/model_0_2025-12-14.12:09:37.pkl\"\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m loadedModel = \u001B[43mjoblib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodelPath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      7\u001B[39m loadedModel.to(device)\n\u001B[32m      8\u001B[39m lastPrediction = generate_tags(\n\u001B[32m      9\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mdescribe this ask \u001B[39m\u001B[33m'\u001B[39m\u001B[33mI don\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt want to system supports products recommendation based on AI\u001B[39m\u001B[33m'\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     10\u001B[39m     loadedModel,\n\u001B[32m     11\u001B[39m     lastTokenizer)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Projects/github-projets/SoftwareCrewIA/.venv/lib/python3.13/site-packages/joblib/numpy_pickle.py:735\u001B[39m, in \u001B[36mload\u001B[39m\u001B[34m(filename, mmap_mode, ensure_native_byte_order)\u001B[39m\n\u001B[32m    733\u001B[39m         obj = _unpickle(fobj, ensure_native_byte_order=ensure_native_byte_order)\n\u001B[32m    734\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m735\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrb\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m    736\u001B[39m         \u001B[38;5;28;01mwith\u001B[39;00m _validate_fileobject_and_memmap(f, filename, mmap_mode) \u001B[38;5;28;01mas\u001B[39;00m (\n\u001B[32m    737\u001B[39m             fobj,\n\u001B[32m    738\u001B[39m             validated_mmap_mode,\n\u001B[32m    739\u001B[39m         ):\n\u001B[32m    740\u001B[39m             \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(fobj, \u001B[38;5;28mstr\u001B[39m):\n\u001B[32m    741\u001B[39m                 \u001B[38;5;66;03m# if the returned file object is a string, this means we\u001B[39;00m\n\u001B[32m    742\u001B[39m                 \u001B[38;5;66;03m# try to load a pickle file generated with an version of\u001B[39;00m\n\u001B[32m    743\u001B[39m                 \u001B[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001B[39;00m\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: '../models/model_0_2025-12-14.16:31:17.pkl'"
     ]
    }
   ],
   "execution_count": 140
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
